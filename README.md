# U-NET D√âTECTION DE FEUX DE FOR√äT PAR S√âGMENTATION D'IMAGE SATELLITE üõ∞Ô∏è

##  üèÅ Description
SAT_FIRE_DETECTION est un projet de Computer Vision visant √† entra√Æner un r√©seau de neuronne √† convolution U-Net afin de d√©tecter les feux de for√™t par segmentation d'images satellites. 

- Algorithme : Le projet met en ≈ìuvre un r√©seau de neurones √† convolution (CNN) bas√© sur l'architecture U-Net. Cette derni√®re est particuli√®rement performante pour les t√¢ches de segmentation d'images, ce qui permet de d√©limiter avec pr√©cision les zones de feu sur les images satellites.

- Dataset : Le mod√®le U-Net est entra√Æn√© sur le dataset cr√©√© et annot√© par l'IRT Saint Exup√©ry, disponible √† cette adresse : https://www.irt-saintexupery.com/fr/firesat/

## ‚≠êÔ∏è Fonctionnalit√©s et Architecture 
Cette section d√©taille les choix techniques et l'impl√©mentation sp√©cifique du r√©seau de neuronne √† convolution U-net.

### üß† Pr√©-traitement et Mod√®le d'Apprentissage
- üñºÔ∏è **Pr√©-traitement des donn√©es** :
    - Lecture des noms d'images et de masques depuis les fichiers `train.txt` pour l'entra√Ænement `val.txt` pour la validation lors de l'entra√Ænement,  et `test.txt` pour le test finale de notre mod√®le apr√®s entra√Ænement. 
    - Chargement des images, s√©paration des canaux RVB et normalisation des valeurs de pixels entre 0 et 1.
    - Standardisation des donn√©es (moyenne=0, √©cart-type=1) pour acc√©l√©rer la convergence.
    - R√©cup√©ration du `Mask` (label) associ√© √† chaque images.
    - Organisation des donn√©es en tenseurs pr√™ts pour l'entra√Ænement.
![Image pr√©traitement 1](fig_readme/Figure_1.png)
![Image pr√©traitement 2](fig_readme/Figure_2.png)
- üèóÔ∏è **Architecture du mod√®le U-Net** :
    - **Structure en U** : Le r√©seau adopte une architecture sym√©trique compos√©e d'une partie contractante (encodeur) et d'une partie expansive (d√©codeur).
    - **Encodeur** : La partie gauche (contractante) utilise des blocs de convolutions suivis de Max-Pooling pour r√©duire progressivement la dimension spatiale des images et extraire des caract√©ristiques de plus en plus complexes.
    - **D√©codeur** : La partie droite (expansive) utilise des convolutions transpos√©es (`ConvTranspose2d`) pour sur-√©chantillonner les cartes de caract√©ristiques et reconstruire une segmentation fine √† la r√©solution d'origine.
    - **Connexions de saut (Skip Connections)** : Des connexions directes relient les couches de l'encodeur √† leurs homologues du d√©codeur. Elles permettent au mod√®le de r√©utiliser les informations spatiales de bas niveau (contours, textures) perdues lors de la contraction, am√©liorant consid√©rablement la pr√©cision de la segmentation.
    - **Sortie** : La couche finale utilise une convolution de taille 1x1 suivie d'une fonction d'activation **Sigmoid**. Cela produit une carte de probabilit√© o√π chaque pixel a une valeur entre 0 et 1, indiquant la probabilit√© qu'il appartienne √† la classe "feu".
![Image U-Net](fig_readme/Figure_7.png)

- üõë **Strat√©gie anti-surapprentissage (Early Stopping)** : Pour √©viter le surapprentissage, une technique d'arr√™t anticip√© est mise en place. L'entra√Ænement est interrompu si la perte de validation ne s'am√©liore pas pendant un nombre d√©fini d'√©poques (patience de 3). Le mod√®le avec la meilleure performance de validation est sauvegard√©.

- üé≤ **Fonction de Perte (Dice Loss)** :
    - La perte est calcul√©e √† l'aide du **Dice Loss** (`1 - Dice Coefficient`), une mesure id√©ale pour les t√¢ches de segmentation.
    - Le Dice Coefficient mesure la similarit√© entre la pr√©diction et le masque r√©el (v√©rit√© terrain), avec une valeur de 1 pour une correspondance parfaite.
    - Cette fonction de perte est particuli√®rement efficace pour les datasets d√©s√©quilibr√©s (comme ici, o√π les pixels de "feu" sont rares par rapport au fond), car elle se concentre sur la correspondance spatiale des r√©gions d'int√©r√™t plut√¥t que sur la pr√©cision pixel par pixel.

### ‚öôÔ∏è Optimisation Multiplateforme :
Le code est optimis√© pour une ex√©cution acc√©l√©r√©e sur diff√©rentes architectures mat√©rielles avec d√©tection automatique de la plateforme :

- Apple Silicon (Mac M1/M2/M3) : Utilisation de l'API Metal Performance Shaders (MPS) pour l'acc√©l√©ration GPU.

- NVIDIA (Windows/Linux) : Utilisation de l'API CUDA pour l'acc√©l√©ration GPU, lorsque disponible.

- CPU (G√©n√©rique) : Bascule automatique sur le CPU lorsque ni MPS ni CUDA n'est d√©tect√©.

## üõ†Ô∏è Pr√©requis et installation

### ‚öôÔ∏è Pr√©requis Logiciels : 
Assurez vous d'avoir : 
   - Python 3.11 (pour meilleure compatibilit√© avec Pytorch)

### üíø Cloner le d√©p√¥t :
   - Avec HTTPS : 
   ```bash
   git clone https://github.com/Belou25/sat_fire_detection.git
   ```
   - Avec SSH : 
   ```bash 
    git clone git@github.com:Belou25/sat_fire_detection.git
   ```

### üêç Installation des D√©pendances Python :

Une fois les pr√©requis syst√®me install√©s (si n√©cessaire), vous pouvez installer toutes les biblioth√®ques Python :

1. Cr√©ez et activez un environnement virtuel (recommand√©) :

```bash
python3.11 -m venv env
source env/bin/activate
```

2. Installez les biblioth√®ques √† partir du fichier requirements.txt :
```bash
pip install -r requirements.txt
```

## üïπÔ∏è Utilisation et Entra√Ænement
### Entra√Æner le mod√®le : 
Pour d√©marrer l'entra√Ænement du mod√®le : 
```bash
python fire_detect_train.py
```

### Visualiser le mod√®le entra√Æn√© : 
Pour visualiser et tester le mod√®le :

```bash 
python fire_detect_test.py
```


## üèõÔ∏è Structure du projet
- `fig_readme/`: dossier contenant certaines images d'illustration du `README.md` 
- `figures/in_episode/`: dossier contenant les graphiques de suivi du `Dice loss`  pour chaque batch de chaque √©pisode.
- `figures/out_episode/`: dossier contenant le graphique de suivi du `Dice loss` moyen sur les donn√©es d'entra√Ænements (Training loss) et de train-test(Validation loss) par √©pisodes. 
- `Model_save_weights/`: dossier contenant le poid du mod√®le entrain√© (mis √† jour √† chaque fin d'√©pisode).
- `Model_save_weights/model_weights2.pth`: poids d'un mod√®le entrain√© fonctionnel. 
- `fire_detect_test.py`: fichier python pour visualisation du mod√®le entra√Æn√©.
- `fire_detect_train.py`: fichier python pour entra√Ænement du mod√®le. 
- `pr√©sentation_detection_feux_for√™ts.pdf`: Rapport du projet.
- `requirements.txt` : liste des frameworks utiles pour l'environemment. 


## üìà R√©sultats 
- **Graphiques de Convergence** : 
![Graphique Dice loss du mod√®le √† l'√©pisode 10](figures/in_episode/episode10.png)
![Graphique Training et Validation Loss](figures/out_episode/graph.png)

- **Images de visualisation des pr√©dictions s√©mantiques du mod√®le** :
![Pr√©diction 1](fig_readme/Figure_3.png)
![Pr√©diction 2](fig_readme/Figure_4.png)
![Pr√©diction 3](fig_readme/Figure_5.png)
![Pr√©diction 4](fig_readme/Figure_6.png)

- **R√©sutats de validation sur le Dataset de Test** :  
![R√©sultats](fig_readme/Figure_8.png)

- **Rapport du projet** : 
Un rapport du projet est diponible dans le d√©p√¥t au nom de : `pr√©sentation_detection_feux_for√™ts.pdf`.

## üíæ D√©tails de l'Entra√Ænement Initial (Poids Fournis)
Les poids du mod√®le pr√©-entra√Æn√© (`model_weights2.pth`) fournis dans ce d√©p√¥t ont √©t√© g√©n√©r√©s dans l'environnement mat√©riel suivant :

- GPU : NVIDIA GeForce RTX 3070 (version portable)

- VRAM D√©d√©e : 8 Go

- RAM Syst√®me : 16 Go

- P√©riode d'Entra√Ænement : 25 minutes (10 √©pisodes) sur une seule session.

- Batch Size Utilis√© : L'entra√Ænement a √©t√© effectu√© avec un petit batch size de 8 pour rester dans la limite des 8 Go de VRAM et garantir la stabilit√©.


## üí° Recommendation pour un Nouvel Entra√Ænement 

Pour quiconque souhaite r√©entra√Æner l'agent sur une machine diff√©rente, il est essentiel d'ajuster les hyperparam√®tres et de surveiller l'utilisation du mat√©riel pour maximiser l'efficacit√©.

1. Adapter la Taille du Batch (`Batch Size`)

La taille du batch de 8, utilis√©e lors de l'entra√Ænement initial, est conservatrice. Si votre machine le permet (plus de 8 Go de VRAM), il est fortement recommand√© d'augmenter le `Batch Size` pour acc√©l√©rer la convergence.

2. Ajuster le Taux d'Apprentissage (`Learning Rate`)

Lorsque vous augmentez le `Batch Size`, le gradient de la fonction de perte devient plus stable et pr√©cis. Pour exploiter cette pr√©cision, vous devez augmenter le `Learning Rate` ($\alpha$) pour √©viter une convergence trop lente. 

3. Surveillance de la Saturation GPU/VRAM

Pour vous assurer que vous utilisez au maximum la puissance de votre carte graphique sans d√©passer la m√©moire, vous devez viser une saturation du GPU/VRAM de 90% ou plus.

- Windows : Gestionnaire des t√¢ches.
- MacOS :
```bash 
sudo powermetrics --samplers cpu_power,gpu_power -i 500
```

## üôã‚Äç‚ôÇÔ∏è Auteur
- Erwan GOURIOU
